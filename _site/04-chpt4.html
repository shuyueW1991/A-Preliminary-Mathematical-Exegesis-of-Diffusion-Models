<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li:not(:nth-child(6)) > a, .site-nav > ul.nav-list:first-child > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(6) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(6) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(6) > ul.nav-list { display: block; } </style> <script src="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/assets/js/vendor/lunr.min.js"></script> <script src="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Chapter 4 - Implementation on machine - get our hands dirty | PrgM2 /pR’gem/2</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="Chapter 4 - Implementation on machine - get our hands dirty" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="A preliminary mathematical exegesis of diffusion models" /> <meta property="og:description" content="A preliminary mathematical exegesis of diffusion models" /> <link rel="canonical" href="http://localhost:4000/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/04-chpt4.html" /> <meta property="og:url" content="http://localhost:4000/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/04-chpt4.html" /> <meta property="og:site_name" content="PrgM2 /pR’gem/2" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Chapter 4 - Implementation on machine - get our hands dirty" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"A preliminary mathematical exegesis of diffusion models","headline":"Chapter 4 - Implementation on machine - get our hands dirty","url":"http://localhost:4000/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/04-chpt4.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/" class="site-title lh-tight"> PrgM2 /pR'gem/2 </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/" class="nav-list-link">Cover Page</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/00-chpt0.html" class="nav-list-link">Chapter 0 - Preface</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/01-chpt1.html" class="nav-list-link">Chapter 1 - The High-Dimensional Structure of True Data</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/02-chpt2.html" class="nav-list-link">Chapter 2 - The ELBO Paradigm --- Proxy Objective for True Data Maximization</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/03-chpt3.html" class="nav-list-link">Chapter 3 - Dissecting the ELBO - Diffusion Models as Distribution-Transitioned Dynamics</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/04-chpt4.html" class="nav-list-link">Chapter 4 - Implementation on machine - get our hands dirty</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/appendix-DDPM.html" class="nav-list-link">Appendix - Code for DDPM</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/resume.html" class="nav-list-link">About Author / Cite this</a></li><li class="nav-list-item"><a href="/A-Preliminary-Mathematical-Exegesis-of-Diffusion-Models/sponsor.html" class="nav-list-link">Buy me coffee(s)</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search PrgM2 /pR'gem/2" aria-label="Search PrgM2 /pR'gem/2" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async=""></script> <div style="text-align: left; font-size: 1.3em;"> Chapter 4 - Implementation on machine - get our hands dirty. </div> <p><br /></p> <div style="text-align: center;"> <img src="./assets/images/fig_ch04.png" style="width: 45%; max-width: 400px; height: auto; margin: 0 auto;" /> </div> <p>Implementation is one of the most beautiful thing that you can experience on earth, because it is the last push from idea on your mind to reality.</p> <p>In the last chapter, we came to know that above all, the training is for noise prediction in the discussion of equivalent loss functions. This chapter is aimed to push mathematics to executable level.</p> <p>We will offer the specific <em>forward</em> distribution transition formula, i.e. the <em>noise-adding</em> procedure, as well as the <em>reverse</em> distribution transition formula, i.e. the <em>denoising</em> procedure in this chapter and in subsequent appendices.</p><hr /> <p>We start from</p> \[\mu(x,t) = -\frac{1}{2}\beta(t),\quad \sigma(x,t) = \sqrt{\beta}\] <p>as solution to our Itô equation. That they push the initial distribution towards a converging gaussian is validated in Chapter 3. <!-- The discrete update rules led by that provides more control for algorithm, e.g. accelerate and de-accelerate in noise schedule. --></p> <p>Start with the SDE:</p> \[dx_t = -\frac{1}{2} \beta(t) x_t \, dt + \sqrt{\beta(t)} \, dW_t\] <p>For a small time step \(\Delta t = 1\), the discretization gives:</p> \[x_t \approx x_{t-1} - \frac{1}{2} \beta(t) x_{t-1} + \sqrt{\beta(t)} \, (W_t - W_{t-1})\] <p>Since \(W_t - W_{t-1} \sim \mathcal{N}(0, \Delta t = 1)\), let \(z_{t-1} = W_t - W_{t-1} \sim \mathcal{N}(0, I)\), we have:</p> \[x_t \approx \left(1 - \frac{1}{2} \beta(t)\right) x_{t-1} + \sqrt{\beta(t)} \, z_{t-1}\] <p>For small \(\beta(t)\), take the first-order Taylor expansion of \(\sqrt{1 - \beta(t)}\):</p> \[\sqrt{1 - \beta(t)} \approx 1 - \frac{1}{2} \beta(t)\] <p>Substitute this into above, we then have:</p> \[x_t = \sqrt{1 - \beta(t)} \, x_{t-1} + \sqrt{\beta(t)} \, z_{t-1}\] <p>as the forward process. Notably, we can have \( \beta(t) \) to be written as \( \beta_t \), just as a new denotation. Thus:</p> \[x_t = \sqrt{1 - \beta_t} \, x_{t-1} + \sqrt{\beta_t} \, \varepsilon_{t-1}, \quad \varepsilon_{t-1} \sim \mathcal{N}(0, I).\] <p>The latter is also known as the noise schedule.</p><hr /> <p>As we recall, the reverse SDE in Chapter 3 claims</p> \[d\mathbf{x} = \left[ \mathbf{\mu}(\mathbf{x}, t) - \sigma(t)^2 \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) \right] dt + \sigma(t) d\bar{\mathbf{w}}_t.\] <p>We then put our solution of \(\mu(x,t)\) and \(\sigma(x,t)\) in it, and thus we have:</p> \[d\mathbf{x} = \left[ -\frac{1}{2}\beta(t) - \beta(t) \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) \right] dt + \sigma(t) d\bar{\mathbf{w}}_t\] <p>where the \(p_t(\mathbf{x})\) is similar to the noise-perturbed distribution that corrupts data with a known noise distribution (e.g., Gaussian) in Chapter 3:</p> \[q_\sigma(\tilde{x}) = \int q_{data}(x) q_\sigma(\tilde{x}|x) dx\] <p>We should establish the expression of \(x_t\) on \(x_0\), because the latter matches \(q_{data}(x)\) in essence. However, we only have the expression of \(x_t\) on \(x_{t-1}\): \(x_t = \sqrt{1 - \beta_t} \, x_{t-1} + \sqrt{\beta_t} \, \varepsilon_{t-1} \), so we accumulate that till \(t=0\), then we have</p> \[x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \, \varepsilon,\] <p>where \(\alpha_t = 1 - \beta_t\), \(\bar{\alpha}_t = \prod_{s=1}^t \alpha_s\), and \(\varepsilon \sim \mathcal{N}(0, I)\).</p> <p>Importantly, we can also rewrite it as</p> \[q(x_t | x_0) = \mathcal{N}\left(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I \right),\] <p>where \(\alpha_t = 1 - \beta_t\), and \(\bar{\alpha}_t = \prod_{s=1}^t \alpha_s\).</p> <p>Make analogy to our analysis to</p> \[\tilde{x} = x + \sigma \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)\] <p>in Chapter 3, according to</p> \[x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \, \varepsilon,\] <p>here, similar to</p> \[\nabla_{\tilde{x}} \log q_\sigma(\tilde{x}|x) = - \frac{\varepsilon}{\sigma}\] <p>there, we have</p> \[\nabla_{x_t} \log p_t(x_t) \approx -\frac{\epsilon_\theta(x_t, t)}{\sqrt{1 - \bar{\alpha}_t}}\] <p>here.</p> <p>However, we wouldn’t like a formalistic analogy to be the foundation of our theory. Let’s pause a little bit and discuss more on this.</p><hr /> <p>First, let’s restate the two scenarios, first being</p> \[\tilde{x} = x + \sigma \epsilon\] <p>and second being:</p> \[x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \, \varepsilon\] <p>In the first scenario, it does no harm to assume \( \tilde{x} = x + \sigma \varepsilon \), then:</p> \[\tilde{x} | x \sim \mathcal{N}(x, \sigma^2)\] <p>The probability density function is:</p> \[q_\sigma(\tilde{x} | x) = \frac{1}{\sqrt{2\pi}\sigma} \exp\left( -\frac{(\tilde{x} - x)^2}{2\sigma^2} \right)\] <p>Taking the logarithm:</p> \[\log q_\sigma(\tilde{x} | x) = -\frac{(\tilde{x} - x)^2}{2\sigma^2} - \log(\sqrt{2\pi}\sigma)\] <p>Now, taking the gradient with respect to \( \tilde{x} \):</p> \[\nabla_{\tilde{x}} \log q_\sigma(\tilde{x} | x) = -\frac{2(\tilde{x} - x)}{2\sigma^2} = -\frac{\tilde{x} - x}{\sigma^2}\] <p>Now, we are so certain that taking the gradient in the second scenario would definitely be</p> \[\nabla_{\tilde{x}} \log q(\tilde{x} | x) = -\frac{2(\tilde{x} - \sqrt{\bar{\alpha}} \, x)}{2(1 - \bar{\alpha})} = -\frac{\tilde{x} - \sqrt{\bar{\alpha}} \, x}{1 - \bar{\alpha}} = -\frac{\varepsilon}{\sqrt{1 - \bar{\alpha}}}\] <p>by solid analogy of Tweedie’s formula.</p><hr /> <p>Ok, now we go back to our case by substituting the score approximation:</p> \[dx_t = \left[ -\frac{1}{2} \beta(t) x_t + \frac{\beta(t)}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right] dt + \sqrt{\beta(t)} \, d\bar{W}_t.\] <p>For small steps (\(\Delta t = 1\)), the reverse update becomes:</p> \[x_{t-1} = x_t - \left[ -\frac{1}{2} \beta_t x_t + \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right] + \sqrt{\beta_t} \, z, \quad z \sim \mathcal{N}(0, I).\] <p>Simplifying it, we have:</p> \[x_{t-1} = \left(1 + \frac{\beta_t}{2}\right) x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) + \sqrt{\beta_t} \, z, \quad z \sim \mathcal{N}(0, I).\] <p><strong>By far, all basic theoretical knowledge for diffusion models is illustrated.</strong> Among most of the diffusion models, all variants use the same loss</p> \[\mathbb{E}[|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)|^2].\] <p>All methods implicitly use Tweedie’s formula to estimate the clean data \(\hat{\mathbf{x}}_0\) from the noisy observation \(\mathbf{x}_t\), where the relationship</p> \[\boldsymbol{\epsilon}_\theta = -\sqrt{1-\bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log p_t(\mathbf{x}_t)\] <p>connects denoising to score matching.</p><hr /> <p>Below in appendices, we will discuss the real code repository for the famous Latent Diffusion Model and other models. Our discussion will include model architecture and its core building blocks, the underlying design rationale and key implementation details, and the connections to other leading diffusion-based approaches, etc. This chapter will remain open-ended by design, allowing for future expansions as new advancements emerge in this rapidly evolving field. It’ll keep growing, fo’ sho’.</p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
